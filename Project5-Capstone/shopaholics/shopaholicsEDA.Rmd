---
title: "shopaholicsEDA"
author: "Jhonasttan Regalado"
date: "12/3/2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/DataScience/bootcamp7/githubcrush/bootcamp007_project/Project5-Capstone/shopaholics/BX-CSV-Dump/")
```

Load libraries
```{r, echo=FALSE}
library(tidyverse)
library(ggmap)
library(ggplot2)
library(anytime)
library(lubridate)
library(leaflet)
library(jsonlite)
library(caret)
library(stringr)

```

Load user data into dataframe and capture geospatial locations
```{r}


users <- read.csv("./BX-Users.csv", sep = ";", header = TRUE, stringsAsFactor=FALSE, quote="\"", encoding = "Latin-1") #encoding="UTF-8")
str(users)

locations <- users %>% group_by(Location) %>% count() %>% arrange(desc(n))

```

Code to get geoCodes

```{r}

userLocationGeoSpatial <- function(x) {
  address <- geocode(location = x)
}

#get address geolocations
#for (i in seq_along(locations$Location)) {
for (i in seq(1501,1700)) {
  locationGeocode <- c(0.0,0.0)
  
  locationGeocode <- tryCatch(
    userLocationGeoSpatial(locations$Location[i]), 
    error=function(e) NULL
    )
  
  if (length(locationGeocode[1]) != 0) {
  
    locations$lon[i] <- locationGeocode[[1]]
    locations$lat[i] <- locationGeocode[[2]]

  }
  
  Sys.sleep(1)
}

write.csv(locations[1:1700,], file = './locations.csv')
```

Load locations with Geocodes
```{r}
locationsGeoCoded <- read.csv("./locations.csv")

```

Cleanup users data
```{r}
#find rows where values equal integers << breaks - may need to remove some rows

#Nulls required for DataBricks SQL (table) environment
#Age
for (i in seq_along(users$Age)) {
    users$Age[i] <- tryCatch(as.integer(users$Age[i]),
                                error=function(e) NA
                                )

}

for (i in seq_along(users$User.ID)) {
    users$User.ID[i] <- tryCatch(as.integer(users$User.ID[i]),
                                error=function(e) NA
                                )

}

for (i in seq_along(users$Location)) {
    users$Location[i] <- tryCatch(as.character(users$Location[i]),
                                error=function(e) NA
                                )

}

#for (i in seq_along(users$AgeInt)) {
#    if (is.na(users$AgeInt[i])) {
#      users$AgeInt[i] <- 0
#    } 
#}

#remove '.' in column names and filter out NAs on UserID
colnames(users) <- c("UserID", "Location", "Age")
write.csv(filter(users, !is.na(UserID)), "./usersCleaned.csv",row.names = FALSE)


#convert column to integer
users$AgeInt <- as.integer(users$AgeInt)
#create cleaned dataset
#usersCleaned <- select(users, User.ID, Location, AgeInt)
#colnames(usersCleaned) <- c("UserID", "Location", "Age")
#write.csv(usersCleaned, "./usersCleaned.csv",row.names = FALSE)

#scrubber >> users$Age <- str_replace_all(users$Age, "&#", "")
#wasn't required  >> users$Age <- str_replace_all(users$Age, "<f3>dzk<69>e", "")

users$User.ID <- as.integer(users$User.ID)

```

View users by age groups -- User data needs cleaning (python??) prior to grouping

```{r}

users %>% filter(AgeInt > 0) %>% ggplot(aes(AgeInt)) + geom_bar()
```

Load books
```{r}
books <- read.csv("./BX-Books-munged.csv",sep = ";", header = TRUE, stringsAsFactor=FALSE, quote="\"")
#books <- read.csv("./BX-Books-munged.csv",sep = ";", header = TRUE)
books$Year.Of.Publication <-  lubridate::year(anydate(books$Year.Of.Publication))

#clean books data set
for (i in seq_along(books)) {
    books[i] <- tryCatch(as.integer(books[i]),
                                error=function(e) NA
                                )

}

for (i in seq_along(books)) {
    books[i] <- tryCatch(as.integer(books[i]),
                                error=function(e) NA
                                )

}

for (i in seq_along(books)) {
    books[i] <- tryCatch(as.character(books[i]),
                                error=function(e) NA
                                )

}

```

Load ratings
```{r}
ratings <- read.csv("./BX-Book-Ratings.csv", sep = ";", header = TRUE, stringsAsFactor=FALSE)

```

EDA

Summary:
```{r}
summary(books)
str(books)
#books$Year.Of.Publication <- as.Date(books$Year.Of.Publication, "%Y")
head(books)
summary(users)
head(users)
summary(ratings)
str(books)
```
Books - 113,679 unique ISBNs without category / subject or country of origin
```{r}
summary(books$Year.Of.Publication)
ggplot(books,aes(Year.Of.Publication)) + geom_histogram()
filter(books,Year.Of.Publication == 2050)
filter(books,Year.Of.Publication != 2050) %>% ggplot(.,aes(Year.Of.Publication)) + geom_histogram()
books %>% group_by(Year.Of.Publication) %>% count() %>% top_n(.,10) %>% arrange(desc(n))
```

Users


Leafmap for visualizing locations - data was also ported to Carto >> https://jhonasttan.carto.com/builder/d2dc0256-ba5f-11e6-bfdd-0e8c56e2ffdb/embed?state=%7B%22map%22%3A%7B%22ne%22%3A%5B-75.14077784070427%2C-211.28906249999997%5D%2C%22sw%22%3A%5B82.35580019800932%2C203.203125%5D%7D%2C%22widgets%22%3A%7B%2225e9dd14-0976-4ce4-b198-6b22eca59f52%22%3A%7B%22normalized%22%3Atrue%7D%7D%7D 
```{r}
#set leaflet map tile
tile_layer <- "https://api.mapbox.com/styles/v1/mapbox/streets-v10/tiles/256/{z}/{x}/{y}?access_token=pk.eyJ1IjoiamhvbmFzdHRhbiIsImEiOiJFLTAzeVVZIn0.mwAAfKtGwv3rs3L61jz87A"

# leaflet(data = users) %>% 
#   addTiles(urlTemplate = tile_layer) %>% 
#   addMarkers(popup = paste0("Station: ", leaflet_info$stationName,
#                             "<br>Bikes: ", leaflet_info$availableBikes, " / Docks: ",
#                             leaflet_info$availableDocks, " / Total Docks: ", leaflet_info$totalDocks)) %>%
#   addCircles(lat = leaflet_info[1:length(input$selected),'latitude'], 
#              lng = leaflet_info[1:length(input$selected),'longitude'],
#              weight = leaflet_info$availableBikes, radius = leaflet_info$availableDocks / input$docksAvailable, 
#              color =  ifelse(leaflet_info$availableBikes >= input$bikesAvailable,"green","red"),
#              #weight = 1, radius = ((leaflet_info$availableBikes + leaflet_info$availableDocks) * 5 ), color =  "black",
#              fillColor = "orange", fillOpacity=0.5, opacity=1) %>%
# setView(lng = -73.976522, lat = 40.7528, zoom = input$zoom)

leaflet(data = locations[1:75,c("Location","lon","lat")]) %>% 
  addTiles(urlTemplate = tile_layer) %>% 
  addMarkers(popup = locations$Location) # %>%
  #setView(lng = -73.976522, lat = 40.7528, zoom = 12)
```

Ratings - how do we handle zero ratings?

```{r}
ggplot(ratings, aes(Book.Rating)) + geom_histogram()
```

Capture Book's current rating and other features from Google API (key not required) - work in progress
Example: https://www.googleapis.com/books/v1/volumes?q=isbn:0195153448

```{r}

#testing
bookUrlStart <- "https://www.googleapis.com/books/v1/volumes?q=isbn:"

isbn <- books$ISBN[1]
bookUrl <- paste0("https://www.googleapis.com/books/v1/volumes?q=isbn:", isbn)
bookJson <- fromJSON(paste(readLines(bookUrl), collapse=""))

booksCatalogue <- data.frame()
googleBooksCat <- list()

#Build book catalogue
isbn
title <- bookJson$items$volumeInfo$title
author <- bookJson$items$volumeInfo$authors #can be more than one 
publishedDate <- bookJson$items$volumeInfo$publishedDate
publisher <- bookJson$items$volumeInfo$publisher
pageCount <- bookJson$items$volumeInfo$pageCount
averageRating <- bookJson$items$volumeInfo$averageRating
ratingsCount <- bookJson$items$volumeInfo$ratingsCount
maturityRating <- bookJson$items$volumeInfo$maturityRating
imageThumbnail <- bookJson$items$volumeInfo$imageLinks$smallThumbnail
infoLink <- bookJson$items$volumeInfo$infoLink
textSnippet <- bookJson$items$searchInfo$textSnippet

#create list for adding to dataframe
googleBooksCat <- list(isbn = isbn, title = title, author = paste(unlist(author), collapse = ", "), 
                       publishedDate = publishedDate, publisher = publisher, pageCount = pageCount, 
                       averageRating = averageRating, ratingsCount = ratingsCount,
                    maturityRating = maturityRating, imageThumbnail = imageThumbnail, 
                    infoLink = infoLink, textSnippet = textSnippet)

#add row to dataframe
#as.data.frame(googleBooksCat)
booksCatalogue <- rbind(booksCatalogue, as.data.frame(googleBooksCat))

for (b in seq_along(books$ISBN)) {
  
  isbn <- books$ISBN[b]
  bookUrl <- paste0("https://www.googleapis.com/books/v1/volumes?q=isbn:", isbn)
  
  bookJson <- fromJSON(paste(readLines(bookUrl), collapse=""))
}
```

Predict Ratings Model
```{r}
set.seed(0)
#divide data into half via sampling to test prediction models
subsetRatingsIndex <- createDataPartition(ratings$User.ID, list=FALSE)
subsetRatings <- ratings[subsetRatingsIndex, ]

tIndex <- createDataPartition(subsetRatings$User.ID, list = FALSE, p=0.7)

train_ratings <- subsetRatings[tIndex,]
test_ratings <- subsetRatings[-tIndex,]
lmRatings <- lm(Book.Rating ~ ., data = train_ratings)


```

