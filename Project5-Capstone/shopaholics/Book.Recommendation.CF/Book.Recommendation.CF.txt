Project5-Capstone/shopaholics/Book.Recommendation.CF/Book.Recommendation.CF.txt

* We experimented Marcel Caraciolo's Collaborative Filtering (CF) [http://aimotion.blogspot.com/2009/11/collaborative-filtering-implementation.html]
on the Book-Crossing Dataset [http://www2.informatik.uni-freiburg.de/~cziegler/BX/].
* Marcel Caraciolo implemented the CF in Python [https://dl.dropboxusercontent.com/u/1977573/recommendations.py]
which can be found here as [Caraciolo.recommendations.py].

Step-1-Baseline
* BRCF.1.Baseline.ipynb is used to check Caraciolo's implementation against the Book-Crossing Dataset.
* Our baseline model produced same results as shown in Caraciolo's article.  
* However, we observed many exceptions occurred during data loading and Caraaciolo only utilized non-zero ratings:
** There are 1,149,781 ratings in BX-Book-Ratings.csv. 
** When loading it to Caraciolo's implementation, there is 1 Value exception and are 49,818 Key exceptions.
** There are only 383,853 non-zero ratings used to build dictionary prefs (for user-based filter) which has 77,805 entries.

We believe we can treat zero ratings as missing values and impute them with average rating.
Let say 100 users bought the Book-A, but only 10 user provided ratings.
We can compute average rating for Book-A based on 10 user ratings and then feed thme back to 90 zero-ratings.
Like a lot of Amazon customers, they buy book without feedback.  But they see the average rating from customers who provided ratings.
Following steps are our approach for such imputation.

Step-2-CleanerData
* BRCF.2.CleanerData.ipynb is used to capture what Caraciolo's implementation used from BX-Books and BX-Book-Ratings and save them in true comma-seaparate files: MC.Books.csv and MC.Ratings.csv.
* We also need to eliminate one line from MC.Ratings.csv with editor:
* Line "130499,,.0330486187,6" as there are more than 3 fields

Step-3-VerifyData
* BRCF.3.VerifyData.ipynb is used to verify MC.Books.csv and MC.Ratings.csv.
* MC.Books.csv and MC.Ratings.csv produced same results as shown in Caraciolo's article. 

Step-4-ImputeImplicit
* BRCF.4.ImputeImplicit.ipynb is used to create Good.Ratings.csv which replace zero ratings with average ratings if available.
** We read 1,149,781 from BX-Book-Ratings.csv.
** 433,671 have non-zero ratings; thus, no impute needed.
** We use average ratings for 494,024 records.
** We can only use zero rating for 222,085 records as buyers of those books not provide rating.
** We wrote 1,149,780 records to Good.ratings.csv
* Thus, we double ratings available for building CF.

Step-5-DataImpact
* BRCF.5.DataImpact.ipynb is to re-examine our baseline model using two times more ratings from Good.Ratings.csv.
* As expected, more ratings changed the recommendations.

(end)
